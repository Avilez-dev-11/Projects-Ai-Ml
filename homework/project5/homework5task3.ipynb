{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3 (55 points): NLP and Attention Mechanism"
      ],
      "metadata": {
        "id": "KA8KIML2gUhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Part 1 (10 points):*\n",
        "Implement the scaled dot-product attention as discussed in class\n",
        "(lecture 14) from scratch (use NumPy and pandas only, no deep learning libraries are\n",
        "allowed for this step)."
      ],
      "metadata": {
        "id": "5TzDceYRgUhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    exps = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=-1, keepdims=True)\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value):\n",
        "    # Calculate the dot product of Q and K^T to computes the similarity between queries and keys.\n",
        "    matmul_qk = np.matmul(query, np.transpose(key, axes=(0, 2, 1)))\n",
        "    # Scale the dot product by the square root of the key dimension.\n",
        "    #    This scaling prevents the dot product from growing too large, which can\n",
        "    #    push the softmax function into regions with extremely small gradients.\n",
        "    dk = key.shape[-1]\n",
        "    scaled_attention_logits = matmul_qk / np.sqrt(dk)\n",
        "    # Apply softmax to normalizes the similarity scores, turning them into probabilities.\n",
        "    attention_weights = softmax(scaled_attention_logits)\n",
        "    # Calculate the weighted sum of the values.\n",
        "    #    This is the context vector, which is a weighted sum of the values,\n",
        "    #    where the weights are the attention weights.\n",
        "    output = np.matmul(attention_weights, value)\n",
        "    return attention_weights, output"
      ],
      "metadata": {
        "id": "A9eMXBYCjU_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "class SelfAttentionEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(SelfAttentionEncoder, self).__init__()\n",
        "        self.units = units\n",
        "        self.wq = tf.keras.layers.Dense(units)\n",
        "        self.wk = tf.keras.layers.Dense(units)\n",
        "        self.wv = tf.keras.layers.Dense(units)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # x shape: (batch_size, seq_len, embedding_dim)\n",
        "        Q = self.wq(x)  # (batch_size, seq_len, units)\n",
        "        K = self.wk(x)  # (batch_size, seq_len, units)\n",
        "        V = self.wv(x)  # (batch_size, seq_len, units)\n",
        "\n",
        "        attention_weights, output = scaled_dot_product_attention(Q, K, V)\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "-pX0tttv-Xd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example Usage ---\n",
        "# Assume we have Q, K, and V matrices:\n",
        "# Q: (batch_size, query_length, d_model)\n",
        "# K: (batch_size, key_length, d_model)\n",
        "# V: (batch_size, value_length, d_model)\n",
        "# For simplicity, let's create some dummy data:\n",
        "Q = np.random.rand(2, 8, 64)  # batch_size=2, query_length=8, d_model=64\n",
        "K = np.random.rand(2, 10, 64) # batch_size=2, key_length=10, d_model=64\n",
        "V = np.random.rand(2, 10, 64) # batch_size=2, value_length=10, d_model=64\n",
        "\n",
        "# Calculate attention\n",
        "attention_weights, output = scaled_dot_product_attention(Q, K, V)\n",
        "\n",
        "# Print the shapes to verify\n",
        "print(\"Attention Weights Shape:\", attention_weights.shape)\n",
        "print(\"Output Shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBbZLjLInW2X",
        "outputId": "956449a8-0896-415d-a6a6-5baf5b1ef6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Weights Shape: (2, 8, 10)\n",
            "Output Shape: (2, 8, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Part 2 (10 points):*\n",
        "\n",
        "Pick any encoder-decoder seq2seq model (as discussed in class) and\n",
        "integrate the scaled dot-product attention in the encoder architecture. You may come\n",
        "up with your own technique of integration or adopt one from literature. Hint: See\n",
        "Bahdanau or Luong attention paper presented in class (lecture 14)."
      ],
      "metadata": {
        "id": "512begd-gUhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class Seq2SeqModel:\n",
        "    def __init__(self, encoder_vocab_size, decoder_vocab_size, embedding_dim, units):\n",
        "        self.encoder = Encoder(encoder_vocab_size, embedding_dim, units)\n",
        "        self.decoder = Decoder(decoder_vocab_size, embedding_dim, units)\n",
        "\n",
        "    def forward(self, inputs, targets, target_token_start):\n",
        "        encoder_output, encoder_hidden = self.encoder.forward(inputs)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        decoder_input = np.array([[target_token_start]] * targets.shape[0])\n",
        "\n",
        "        predictions = []\n",
        "        for t in range(1, targets.shape[1]):\n",
        "            context_vector, attention_weights = self.decoder.attention(decoder_hidden, encoder_output)\n",
        "\n",
        "            decoder_output, decoder_hidden = self.decoder.gru(np.concatenate([(decoder_input, context_vector)], axis=-1), decoder_hidden)\n",
        "\n",
        "            prediction = self.decoder.forward(decoder_output, x, decoder_hidden, encoder_output)\n",
        "\n",
        "            predictions.append(prediction)\n",
        "\n",
        "            decoder_input = np.expand_dims(targets[:, t], 1) # Using teacher forcing\n",
        "\n",
        "        return np.stack(predictions, axis=1)\n",
        "\n",
        "class Encoder:\n",
        "    def __init__(self, vocab_size, embedding_dim, units):\n",
        "        self.embedding = np.random.randn(vocab_size, embedding_dim)\n",
        "        self.attention = SelfAttentionEncoder(units)\n",
        "        self.gru = GRU(units, embedding_dim)\n",
        "        self.units = units\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = self.embedding[x]\n",
        "        # Initialize hidden state\n",
        "        hidden = np.zeros((batch_size, self.units))\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(x.shape[1]):\n",
        "            output, hidden = self.gru(x[:, t, :], hidden)\n",
        "            outputs.append(output)\n",
        "\n",
        "        outputs = np.stack(outputs, axis=1)\n",
        "        return outputs, hidden\n",
        "\n",
        "class Decoder:\n",
        "    def __init__(self, vocab_size, embedding_dim, units):\n",
        "        self.embedding = np.random.randn(vocab_size, embedding_dim)\n",
        "        self.gru = GRU(units, embedding_dim)\n",
        "        self.fc = np.random.randn(units, vocab_size)\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = BahdanauAttention(units)\n",
        "        self.W1 = np.random.randn(units, units)\n",
        "        self.V = np.random.randn(units, 1)\n",
        "\n",
        "    def forward(self, x, hidden, encoder_output):\n",
        "        x = self.embedding[x]\n",
        "\n",
        "        context_vector, attention_weights = self.attention(hidden, encoder_output)\n",
        "        x = np.concatenate([np.expand_dims(x, 1), context_vector], axis=-1)\n",
        "\n",
        "        output, state = self.gru(x, hidden)\n",
        "        output = np.reshape(output, (-1, output.shape[2]))\n",
        "        x = np.dot(output, self.fc)\n",
        "        return x, state\n",
        "\n",
        "class BahdanauAttention:\n",
        "    def __init__(self, units):\n",
        "        self.W1 = np.random.randn(units, units)\n",
        "        self.W2 = np.random.randn(units, units)\n",
        "        self.V = np.random.randn(units, 1)\n",
        "\n",
        "    def __call__(self, query, values):\n",
        "        query_with_time_axis = np.expand_dims(query, 1)\n",
        "        score = np.dot(np.tanh(np.dot(query_with_time_axis, self.W1) + np.dot(values, self.W2)), self.V)\n",
        "        attention_weights = np.exp(score) / np.sum(np.exp(score), axis=1, keepdims=True)\n",
        "        context_vector = np.sum(attention_weights * values, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "class GRU:\n",
        "    def __init__(self, units, input_size):\n",
        "        self.units = units\n",
        "        self.W_z = np.random.randn(input_size, units)\n",
        "        self.W_r = np.random.randn(input_size, units)\n",
        "        self.W_h = np.random.randn(input_size, units)\n",
        "        self.U_z = np.random.randn(units, units)\n",
        "        self.U_r = np.random.randn(units, units)\n",
        "        self.U_h = np.random.randn(units, units)\n",
        "        self.b_z = np.zeros(units)\n",
        "        self.b_r = np.zeros(units)\n",
        "        self.b_h = np.zeros(units)\n",
        "\n",
        "    def __call__    (self, x, hidden):\n",
        "        z = self.sigmoid(np.dot(x, self.W_z) + np.dot(hidden, self.U_z) + self.b_z)\n",
        "        r = self.sigmoid(np.dot(x, self.W_r) + np.dot(hidden, self.U_r) + self.b_r)\n",
        "        h_tilde = np.tanh(np.dot(x, self.W_h) + np.dot(r * hidden, self.U_h) + self.b_h)\n",
        "        hidden = (1 - z) * hidden + z * h_tilde\n",
        "        return hidden, hidden\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "QL1D2q2lpyVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Part 3 (5 points):*\n",
        "\n",
        "Pick any public dataset of your choice (use a small-scale dataset like a\n",
        "subset of the Tatoeba or Multi30k dataset) for machine translation task. Train your\n",
        "model from Part 2 for the machine translation task. Evaluate test set by reporting the\n",
        "BLEU Score."
      ],
      "metadata": {
        "id": "EgnALg64gUhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splits = {'train': 'train.jsonl', 'validation': 'val.jsonl', 'test': 'test.jsonl'}\n",
        "df = pd.read_json(\"hf://datasets/ryan82/multi30k_fr/\" + splits[\"train\"], lines=True)"
      ],
      "metadata": {
        "id": "cJ5JiNUVTzyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "qP7_9sWXCAej",
        "outputId": "a8e87843-f45f-49c6-8f9d-d8d74f313e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      en  \\\n",
              "0      Two young, White males are outside near many b...   \n",
              "1      Several men in hard hats are operating a giant...   \n",
              "2        A little girl climbing into a wooden playhouse.   \n",
              "3      A man in a blue shirt is standing on a ladder ...   \n",
              "4               Two men are at the stove preparing food.   \n",
              "...                                                  ...   \n",
              "28996  A rock climber practices on a rock climbing wall.   \n",
              "28997  Two male construction workers are working on a...   \n",
              "28998  An elderly man sits outside a storefront accom...   \n",
              "28999  A man in shorts and a Hawaiian shirt leans ove...   \n",
              "29000                                                      \n",
              "\n",
              "                                                      fr  \n",
              "0      Deux jeunes hommes blancs sont dehors près de ...  \n",
              "1      Plusieurs hommes en casque font fonctionner un...  \n",
              "2      Une petite fille grimpe dans une maisonnette e...  \n",
              "3      Un homme dans une chemise bleue se tient sur u...  \n",
              "4          Deux hommes aux fourneaux préparent à manger.  \n",
              "...                                                  ...  \n",
              "28996       Un alpinisme s'exerce sur un mur d'escalade.  \n",
              "28997  Deux ouvriers travaillent sur la rue à l'extér...  \n",
              "28998  Un vieil homme est assis devant une vitrine ac...  \n",
              "28999  Un homme en short et chemise hawaïenne se penc...  \n",
              "29000                                                     \n",
              "\n",
              "[29001 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e67eedc-95d8-4efd-bbf6-94f1f45342d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two young, White males are outside near many b...</td>\n",
              "      <td>Deux jeunes hommes blancs sont dehors près de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several men in hard hats are operating a giant...</td>\n",
              "      <td>Plusieurs hommes en casque font fonctionner un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A little girl climbing into a wooden playhouse.</td>\n",
              "      <td>Une petite fille grimpe dans une maisonnette e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A man in a blue shirt is standing on a ladder ...</td>\n",
              "      <td>Un homme dans une chemise bleue se tient sur u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Two men are at the stove preparing food.</td>\n",
              "      <td>Deux hommes aux fourneaux préparent à manger.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28996</th>\n",
              "      <td>A rock climber practices on a rock climbing wall.</td>\n",
              "      <td>Un alpinisme s'exerce sur un mur d'escalade.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28997</th>\n",
              "      <td>Two male construction workers are working on a...</td>\n",
              "      <td>Deux ouvriers travaillent sur la rue à l'extér...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28998</th>\n",
              "      <td>An elderly man sits outside a storefront accom...</td>\n",
              "      <td>Un vieil homme est assis devant une vitrine ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28999</th>\n",
              "      <td>A man in shorts and a Hawaiian shirt leans ove...</td>\n",
              "      <td>Un homme en short et chemise hawaïenne se penc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29000</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29001 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e67eedc-95d8-4efd-bbf6-94f1f45342d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e67eedc-95d8-4efd-bbf6-94f1f45342d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e67eedc-95d8-4efd-bbf6-94f1f45342d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c1e02d32-db8b-4b19-b0e2-73917d2bffb5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1e02d32-db8b-4b19-b0e2-73917d2bffb5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c1e02d32-db8b-4b19-b0e2-73917d2bffb5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fc478046-f9d0-4df4-9baa-017db58d7cb3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fc478046-f9d0-4df4-9baa-017db58d7cb3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 29001,\n  \"fields\": [\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28992,\n        \"samples\": [\n          \"Little boy pulling a green wagon wearing a sweatshirt and boots.\",\n          \"Three dancers wearing red sashes perform on a darkened stage.\",\n          \"A man, wearing an official jacket and hat, is leaning against a rail while reading a newspaper.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28969,\n        \"samples\": [\n          \"Une femme distribue des tracts aux gens qui passent.\",\n          \"Un footballeur de Roosevelt percute le ballon et un adversaire pendant un match.\",\n          \"Un chien mord la patte d'un cheval.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = df['en'].tolist()\n",
        "french_sentences = df['fr'].tolist()\n",
        "from collections import Counter\n",
        "# Function to build a vocabulary from sentences\n",
        "def build_vocab(sentences, max_tokens=None):\n",
        "    token_counter = Counter()\n",
        "    for sentence in sentences:\n",
        "        tokens = sentence.lower().split()  # Simple tokenization by splitting on spaces\n",
        "        token_counter.update(tokens)\n",
        "\n",
        "    # Limit vocabulary size if max_tokens is specified\n",
        "    if max_tokens:\n",
        "        vocab = [token for token, _ in token_counter.most_common(max_tokens)]\n",
        "    else:\n",
        "        vocab = list(token_counter.keys())\n",
        "\n",
        "    # Add special tokens\n",
        "    vocab = ['<pad>', '<start>', '<end>', '<unk>'] + vocab\n",
        "    return {token: idx for idx, token in enumerate(vocab)}\n",
        "\n",
        "# Function to tokenize and vectorize sentences\n",
        "def vectorize_sentences(sentences, vocab, max_sequence_length):\n",
        "    sequences = []\n",
        "    for sentence in sentences:\n",
        "        tokens = sentence.lower().split()\n",
        "        sequence = [vocab.get(token, vocab['<unk>']) for token in tokens]  # Convert tokens to indices\n",
        "        sequence = sequence[:max_sequence_length]  # Truncate if longer than max_sequence_length\n",
        "        sequence = sequence + [vocab['<pad>']] * (max_sequence_length - len(sequence))  # Pad if shorter\n",
        "        sequences.append(sequence)\n",
        "    return np.array(sequences)\n",
        "\n",
        "# Build vocabularies\n",
        "max_tokens = 30000\n",
        "max_sequence_length = 50\n",
        "english_vocab = build_vocab(english_sentences, max_tokens)\n",
        "french_vocab = build_vocab(french_sentences, max_tokens)\n",
        "\n",
        "# Vectorize sentences\n",
        "english_sequences = vectorize_sentences(english_sentences, english_vocab, max_sequence_length)\n",
        "french_sequences = vectorize_sentences(french_sentences, french_vocab, max_sequence_length)\n",
        "\n",
        "# Get vocabulary sizes\n",
        "encoder_vocab_size = len(english_vocab)\n",
        "decoder_vocab_size = len(french_vocab)\n"
      ],
      "metadata": {
        "id": "jNNW4myMWEa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"encoder_vocab_size: {encoder_vocab_size}, decoder_vocab_size: {decoder_vocab_size}\")\n",
        "print(\"English sequences sample:\", english_sequences[0])\n",
        "print(\"French sequences sample:\", french_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjSE17QQ-OH6",
        "outputId": "1834429f-302c-447b-88fd-cfb58a6e2801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_vocab_size: 14450, decoder_vocab_size: 16694\n",
            "English sequences sample: [  13 1347   22  824   15   63   72  167 1648    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "French sequences sample: [  17   69   36  221   23  130   59    6 1904    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "    # Create a mask to ignore padding tokens (assume padding token index is 0)\n",
        "    mask = (real != 0).astype(np.float32)\n",
        "\n",
        "    # Compute the cross-entropy loss manually\n",
        "    loss = -np.sum(np.log(pred[np.arange(pred.shape[0]), :, real]) * mask) / np.sum(mask)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Training loop\n",
        "def train_step(model, inputs, targets, optimizer, target_token_start):\n",
        "    # Forward pass\n",
        "    predictions = model.forward(inputs, targets, target_token_start)\n",
        "\n",
        "    # Compute loss (ignore the first token in targets for teacher forcing)\n",
        "    loss = loss_function(targets[:, 1:], predictions)\n",
        "\n",
        "    # Backward pass (compute gradients manually)\n",
        "    gradients = compute_gradients(model, inputs, targets, loss_function)\n",
        "\n",
        "    # Update model parameters using the optimizer\n",
        "    optimizer.update_parameters(model, gradients)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Function to compute gradients manually\n",
        "def compute_gradients(model, inputs, targets, loss_function):\n",
        "    gradients = {}\n",
        "    epsilon = 1e-5  # Small value for finite differences\n",
        "\n",
        "    for param_name, param_value in model.parameters.items():\n",
        "        grad = np.zeros_like(param_value)\n",
        "\n",
        "        # Iterate over each parameter value and compute the gradient\n",
        "        for idx in np.ndindex(param_value.shape):\n",
        "            original_value = param_value[idx]\n",
        "\n",
        "            # Perturb the parameter\n",
        "            param_value[idx] += epsilon\n",
        "            loss_plus = loss_function(targets[:, 1:], model.forward(inputs, targets))\n",
        "\n",
        "            param_value[idx] -= 2 * epsilon\n",
        "            loss_minus = loss_function(targets[:, 1:], model.forward(inputs, targets))\n",
        "\n",
        "            # Reset the parameter\n",
        "            param_value[idx] = original_value\n",
        "\n",
        "            # Compute the gradient using finite differences\n",
        "            grad[idx] = (loss_plus - loss_minus) / (2 * epsilon)\n",
        "\n",
        "        gradients[param_name] = grad\n",
        "\n",
        "    return gradients"
      ],
      "metadata": {
        "id": "cduzw1CxYlsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGDOptimizer:\n",
        "    def __init__(self, learning_rate):\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def update_parameters(self, model, gradients):\n",
        "        \"\"\"\n",
        "        Updates model parameters using SGD.\n",
        "\n",
        "        Args:\n",
        "            model: The Seq2Seq model.\n",
        "            gradients: A dictionary of gradients for each model parameter.\n",
        "        \"\"\"\n",
        "        for param_name, param_value in model.parameters.items():\n",
        "            param_value -= self.learning_rate * gradients[param_name]"
      ],
      "metadata": {
        "id": "ogBqKYBYAN78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "# Define the target_token_start token\n",
        "target_token_start = french_vocab['<start>']\n",
        "\n",
        "# Initialize the model\n",
        "model = Seq2SeqModel(encoder_vocab_size, decoder_vocab_size, embedding_dim, units)\n",
        "optimizer = SGDOptimizer(learning_rate)"
      ],
      "metadata": {
        "id": "WzKzxAc6Yg9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for inputs, targets in zip(english_sequences, french_sequences):\n",
        "        inputs = np.expand_dims(inputs, axis=0)  # Add batch dimension\n",
        "        targets = np.expand_dims(targets, axis=0)  # Add batch dimension\n",
        "\n",
        "        loss = train_step(model, inputs, targets, optimizer, target_token_start)\n",
        "        total_loss += loss\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(english_sequences)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "ALYdxm14YqVp",
        "outputId": "6ff2c0d3-a2d1-4b0d-b905-f0cba9403294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 1) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-918a53d9ec76>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_token_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-8aa9e2d9477c>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, inputs, targets, optimizer, target_token_start)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_token_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_token_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Compute loss (ignore the first token in targets for teacher forcing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-175990ba935b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets, target_token_start)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 1) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Pe7n6hI_EtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pwrx41c0TsdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Part 4 (30 points):*\n",
        "In this part you are required to implement a simplified Transformer\n",
        "model from scratch (using Python and NumPy/PyTorch/TensorFlow with minimal high-\n",
        "level abstractions) and apply it to a machine translation task (e.g., English-to-French or\n",
        "English-to-German translation) using the same dataset from part 3.\n",
        "\n",
        "We discussed Transformer architecture in depth in class (Vaswani Paper – Attention is\n",
        "all you need). Apply the following simplifications to the original model architecture:\n",
        "1. Reduced Model Depth: Use 2 encoder layers and 2 decoder layers instead of the standard 6.\n",
        "2. Limited Attention Heads: Use 2 attention heads in the multi-head attention mechanism rather than 8.\n",
        "3. Smaller Embedding Size: Set the embedding dimension to 64 instead of 512.\n",
        "4. Reduced Feedforward Network Size: Use a feedforward dimension of 128 instead of 2048.\n",
        "5. Smaller Dataset: Use a small dataset (e.g., about 10k sentence pairs).\n",
        "6. Tokenization Simplifications: Use a basic subword tokenizer (like Byte Pair Encoding - BPE) or word-level tokenization instead of complex language-specific tokenizers.\n",
        "\n",
        "**Key components to implement:**\n",
        "1. Positional Encoding: Implement Sinusoidal position encoding.\n",
        "2. Scaled dot-product attention: Use the same implementation from part 1.\n",
        "Projects in Machine Learning and AI (RPI Spring 2025)\n",
        "3. Multi-Head Attention: Integrate the scaled dot-product attention into a multi-\n",
        "head attention framework using the specified simplifications.\n",
        "4. Encoder and Decoder Blocks: Implement simplified encoder and decoder\n",
        "layers, ensuring: Layer normalization, Residual connections, Masked attention in\n",
        "the decoder for autoregressive generation.\n",
        "5. Final Output Layer: Implement a linear layer followed by a SoftMax activation\n",
        "for generating translated tokens.\n",
        "\n",
        "\n",
        "**Evaluation:** Compute the BLEU score on a validation set and compare the performance\n",
        "with your model from part 2. Explain why there are differences in performance. Also\n",
        "discuss any other differences you notice, for example runtime etc."
      ],
      "metadata": {
        "id": "7zRyqbGIgUhN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "h5vnIrS6gUhN"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}